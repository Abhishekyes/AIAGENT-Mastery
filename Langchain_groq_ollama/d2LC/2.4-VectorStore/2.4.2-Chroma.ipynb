{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chroma\n",
    "Chroma is a AI-native open-source vector database focused on developer productivity and happiness. Chroma is licensed under Apache 2.0.\n",
    "\n",
    "https://python.langchain.com/v0.2/docs/integrations/vectorstores/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (590507680.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mpip install speechrecognition pyttsx3 pyaudio torch python-dotenv requests SpeechRecognition pyttsx3 python-dotenv websocket-client SpeechRecognition pyttsx3\u001b[39m\n        ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install speechrecognition pyttsx3 pyaudio torch python-dotenv requests SpeechRecognition pyttsx3 python-dotenv websocket-client SpeechRecognition pyttsx3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voice Chatbot is running. Speak into the microphone...\n",
      "Listening...\n",
      "You said: hello\n",
      "Error: 400 {\"error\":{\"message\":\"Offer did not have an audio media section.\",\"type\":\"invalid_request_error\",\"code\":\"invalid_offer\"}}\n",
      "Chatbot: Sorry, I encountered an error.\n",
      "Listening...\n",
      "Sorry, I did not understand what you said. Please try again.\n",
      "Listening...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 90\u001b[39m\n\u001b[32m     87\u001b[39m             \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAn error occurred:\u001b[39m\u001b[33m\"\u001b[39m, e)\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     \u001b[43mlisten_and_respond\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 68\u001b[39m, in \u001b[36mlisten_and_respond\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     66\u001b[39m     recognizer.adjust_for_ambient_noise(source)\n\u001b[32m     67\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mListening...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m     audio = \u001b[43mrecognizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlisten\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[38;5;66;03m# Convert speech to text using Google Speech Recognition (requires internet)\u001b[39;00m\n\u001b[32m     70\u001b[39m input_text = recognizer.recognize_google(audio)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages/speech_recognition/__init__.py:460\u001b[39m, in \u001b[36mRecognizer.listen\u001b[39m\u001b[34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[39m\n\u001b[32m    458\u001b[39m result = \u001b[38;5;28mself\u001b[39m._listen(source, timeout, phrase_time_limit, snowboy_configuration, stream)\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages/speech_recognition/__init__.py:530\u001b[39m, in \u001b[36mRecognizer._listen\u001b[39m\u001b[34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[39m\n\u001b[32m    527\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m phrase_time_limit \u001b[38;5;129;01mand\u001b[39;00m elapsed_time - phrase_start_time > phrase_time_limit:\n\u001b[32m    528\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m530\u001b[39m buffer = \u001b[43msource\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCHUNK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) == \u001b[32m0\u001b[39m: \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# reached end of the stream\u001b[39;00m\n\u001b[32m    532\u001b[39m frames.append(buffer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages/speech_recognition/__init__.py:191\u001b[39m, in \u001b[36mMicrophone.MicrophoneStream.read\u001b[39m\u001b[34m(self, size)\u001b[39m\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, size):\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpyaudio_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages/pyaudio/__init__.py:570\u001b[39m, in \u001b[36mPyAudio.Stream.read\u001b[39m\u001b[34m(self, num_frames, exception_on_overflow)\u001b[39m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_input:\n\u001b[32m    568\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNot input stream\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    569\u001b[39m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[32m--> \u001b[39m\u001b[32m570\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    571\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py:833: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voice Chatbot is running. Speak into the microphone...\n",
      "Listening...\n",
      "Sorry, I did not understand what you said. Please try again.\n",
      "Listening...\n",
      "You said: hello I am audible\n",
      "Chatbot: hello I am audible, I'm audible\n",
      "Listening...\n",
      "You said: give me reply your best way\n",
      "Chatbot: give me reply your best way to communicate\n",
      "Listening...\n",
      "You said: can you tell me the list of\n",
      "Chatbot: can you tell me the list of the games you have?\n",
      "Listening...\n",
      "You said: hello\n",
      "Chatbot: hello mathematik's mom\n",
      "Listening...\n",
      "Sorry, I did not understand what you said. Please try again.\n",
      "Listening...\n",
      "Sorry, I did not understand what you said. Please try again.\n",
      "Listening...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Disable parallelism to avoid TOKENIZERS_PARALLELISM warning\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Load environment variables from .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Load the model and tokenizer using your HF token\n",
    "model_name = 'microsoft/DialoGPT-small'  # Replace with your desired model if needed\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=hf_token)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, use_auth_token=hf_token)\n",
    "\n",
    "def generate_response(text):\n",
    "    # Encode the input text with special tokens\n",
    "    input_ids = tokenizer.encode(text, return_tensors='pt', add_special_tokens=True)\n",
    "    # Create an attention mask (1 for tokens, 0 for padding if available)\n",
    "    if tokenizer.pad_token_id is not None:\n",
    "        attention_mask = (input_ids != tokenizer.pad_token_id).long()\n",
    "    else:\n",
    "        attention_mask = torch.ones(input_ids.shape, dtype=torch.long)\n",
    "    \n",
    "    # Generate a response using the attention mask\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_length=50,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return response\n",
    "\n",
    "# Initialize the text-to-speech engine\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "def speak(text):\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "# Initialize the speech recognizer and microphone\n",
    "recognizer = sr.Recognizer()\n",
    "microphone = sr.Microphone()\n",
    "\n",
    "def listen_and_respond():\n",
    "    print(\"Voice Chatbot is running. Speak into the microphone...\")\n",
    "    while True:\n",
    "        try:\n",
    "            with microphone as source:\n",
    "                recognizer.adjust_for_ambient_noise(source)\n",
    "                print(\"Listening...\")\n",
    "                audio = recognizer.listen(source)\n",
    "            \n",
    "            # Convert spoken input into text using Google Speech Recognition\n",
    "            input_text = recognizer.recognize_google(audio)\n",
    "            print(\"You said:\", input_text)\n",
    "            \n",
    "            # Generate a chatbot response\n",
    "            response_text = generate_response(input_text)\n",
    "            print(\"Chatbot:\", response_text)\n",
    "            \n",
    "            # Speak out the chatbot response\n",
    "            speak(response_text)\n",
    "        \n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Sorry, I did not understand what you said. Please try again.\")\n",
    "        except sr.RequestError as e:\n",
    "            print(\"Speech recognition error; check your internet connection. Error:\", e)\n",
    "        except Exception as e:\n",
    "            print(\"An error occurred:\", e)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    listen_and_respond()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (1.0.1)\n",
      "Requirement already satisfied: langchain in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (0.3.20)\n",
      "Requirement already satisfied: chromadb in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (0.6.3)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.41 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from langchain) (0.3.45)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from langchain) (0.3.6)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from langchain) (0.3.14)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from langchain) (2.0.39)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: build>=1.0.3 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from chromadb) (1.2.2.post1)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from chromadb) (0.7.6)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from chromadb) (0.115.11)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
      "Requirement already satisfied: numpy>=1.22.5 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from chromadb) (1.26.4)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from chromadb) (3.20.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from chromadb) (4.12.2)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from chromadb) (1.21.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from chromadb) (1.31.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from chromadb) (1.31.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from chromadb) (0.52b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from chromadb) (1.31.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from chromadb) (0.21.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from chromadb) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from chromadb) (1.71.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from chromadb) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from chromadb) (0.15.2)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from chromadb) (32.0.1)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from chromadb) (9.0.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from chromadb) (5.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from chromadb) (3.10.15)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from chromadb) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from chromadb) (13.9.4)\n",
      "Requirement already satisfied: packaging>=19.1 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from build>=1.0.3->chromadb) (24.2)\n",
      "Requirement already satisfied: pyproject_hooks in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from fastapi>=0.95.2->chromadb) (0.46.1)\n",
      "Requirement already satisfied: anyio in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb) (4.8.0)\n",
      "Requirement already satisfied: certifi in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
      "Requirement already satisfied: idna in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (1.33)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: coloredlogs in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
      "Requirement already satisfied: protobuf in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (5.29.3)\n",
      "Requirement already satisfied: sympy in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (1.13.3)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.6.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.69.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.31.0 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.31.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.31.0 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.31.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.52b0 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.52b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.52b0 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.52b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.52b0 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.52b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.52b0 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.52b0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from opentelemetry-instrumentation==0.52b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
      "Requirement already satisfied: asgiref~=3.0 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from opentelemetry-instrumentation-asgi==0.52b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from rich>=10.11.0->chromadb) (2.19.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from tokenizers>=0.13.2->chromadb) (0.29.3)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.4)\n",
      "Requirement already satisfied: websockets>=10.4 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: filelock in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.41->langchain) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded HF_TOKEN: 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\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhishek/Desktop/AIAGENT-KRISH/Langchain_groq_ollama/venv/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:195: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v4 of SentenceTransformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized embedding model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 3, updating n_results = 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created and documents stored.\n",
      "\n",
      "Query Results:\n",
      "Result 1:\n",
      "Content: LangChain is a framework for developing applications powered by language models.\n",
      "Metadata: {}\n",
      "--------------------------------------------------\n",
      "Result 2:\n",
      "Content: Hugging Face provides state-of-the-art models for a wide range of NLP tasks.\n",
      "Metadata: {}\n",
      "--------------------------------------------------\n",
      "Result 3:\n",
      "Content: Chroma is a vector database for storing embeddings and supports similarity search.\n",
      "Metadata: {}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load Environment Variables\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Load environment variables from a .env file\n",
    "hf_token = os.getenv(\"HF_TOKEN\")  # Retrieve your Hugging Face token\n",
    "print(\"Loaded HF_TOKEN:\", hf_token)  # (Debugging only – remove or secure in production)\n",
    "\n",
    "# Step 2: Import Required Libraries\n",
    "# We import the HuggingFaceEmbeddings, Chroma vector store, and Document class from LangChain.\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "# Step 3: Create Sample Documents\n",
    "documents = [\n",
    "    Document(page_content=\"LangChain is a framework for developing applications powered by language models.\"),\n",
    "    Document(page_content=\"Chroma is a vector database for storing embeddings and supports similarity search.\"),\n",
    "    Document(page_content=\"Hugging Face provides state-of-the-art models for a wide range of NLP tasks.\")\n",
    "]\n",
    "\n",
    "# Step 4: Initialize the Embedding Model\n",
    "# Instead of passing hf_token directly, we include it in model_kwargs.\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    model_kwargs={\"use_auth_token\": hf_token}\n",
    ")\n",
    "print(\"Initialized embedding model.\")\n",
    "\n",
    "# Alternative:\n",
    "# You can try a different model by changing the model_name, e.g.,\n",
    "# model_name=\"sentence-transformers/paraphrase-MiniLM-L3-v2\"\n",
    "\n",
    "# Step 5: Create a Chroma Vector Store and Store the Documents\n",
    "# We create the vector store by converting the documents to embeddings.\n",
    "# Optionally, set persist_directory if you want to save the vector DB on disk.\n",
    "vectorstore = Chroma.from_documents(documents, embedding_model)\n",
    "print(\"Vector store created and documents stored.\")\n",
    "\n",
    "# Step 6: Query the Vector Store\n",
    "# Perform a similarity search using a query string.\n",
    "query = \"What is LangChain?\"\n",
    "results = vectorstore.similarity_search(query)\n",
    "\n",
    "# Step 7: Print the Retrieved Results\n",
    "print(\"\\nQuery Results:\")\n",
    "for i, doc in enumerate(results):\n",
    "    print(f\"Result {i+1}:\")\n",
    "    print(\"Content:\", doc.page_content)\n",
    "    print(\"Metadata:\", getattr(doc, 'metadata', \"No metadata\"))\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## building a sample vectordb\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='The world must be made safe for democracy. Its peace must be planted upon the tested foundations of political liberty. We have no selfish ends to serve. We desire no conquest, no dominion. We seek no indemnities for ourselves, no material compensation for the sacrifices we shall freely make. We are but one of the champions of the rights of mankind. We shall be satisfied when those rights have been made as secure as the faith and the freedom of nations can make them.\\n\\nJust because we fight without rancor and without selfish object, seeking nothing for ourselves but what we shall wish to share with all free peoples, we shall, I feel confident, conduct our operations as belligerents without passion and ourselves observe with proud punctilio the principles of right and of fair play we profess to be fighting for.\\n\\n…\\n\\nIt will be all the easier for us to conduct ourselves as belligerents in a high spirit of right and fairness because we act without animus, not in enmity toward a people or with the desire to bring any injury or disadvantage upon them, but only in armed opposition to an irresponsible government which has thrown aside all considerations of humanity and of right and is running amuck. We are, let me say again, the sincere friends of the German people, and shall desire nothing so much as the early reestablishment of intimate relations of mutual advantage between us—however hard it may be for them, for the time being, to believe that this is spoken from our hearts.\\n\\nWe have borne with their present government through all these bitter months because of that friendship—exercising a patience and forbearance which would otherwise have been impossible. We shall, happily, still have an opportunity to prove that friendship in our daily attitude and actions toward the millions of men and women of German birth and native sympathy who live among us and share our life, and we shall be proud to prove it toward all who are in fact loyal to their neighbors and to the government in the hour of test. They are, most of them, as true and loyal Americans as if they had never known any other fealty or allegiance. They will be prompt to stand with us in rebuking and restraining the few who may be of a different mind and purpose. If there should be disloyalty, it will be dealt with with a firm hand of stern repression; but, if it lifts its head at all, it will lift it only here and there and without countenance except from a lawless and malignant few.\\n\\nIt is a distressing and oppressive duty, gentlemen of the Congress, which I have performed in thus addressing you. There are, it may be, many months of fiery trial and sacrifice ahead of us. It is a fearful thing to lead this great peaceful people into war, into the most terrible and disastrous of all wars, civilization itself seeming to be in the balance. But the right is more precious than peace, and we shall fight for the things which we have always carried nearest our hearts—for democracy, for the right of those who submit to authority to have a voice in their own governments, for the rights and liberties of small nations, for a universal dominion of right by such a concert of free peoples as shall bring peace and safety to all nations and make the world itself at last free.\\n\\nTo such a task we can dedicate our lives and our fortunes, everything that we are and everything that we have, with the pride of those who know that the day has come when America is privileged to spend her blood and her might for the principles that gave her birth and happiness and the peace which she has treasured. God helping her, she can do no other.', metadata={'source': 'speech.txt'})]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = TextLoader(\"speech.txt\")\n",
    "data = loader.load()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "splits = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_chroma.vectorstores.Chroma at 0x2d92b121a50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding=OllamaEmbeddings()\n",
    "vectordb=Chroma.from_documents(documents=splits,embedding=embedding)\n",
    "vectordb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To such a task we can dedicate our lives and our fortunes, everything that we are and everything that we have, with the pride of those who know that the day has come when America is privileged to spend her blood and her might for the principles that gave her birth and happiness and the peace which she has treasured. God helping her, she can do no other.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## query it\n",
    "query = \"What does the speaker believe is the main reason the United States should enter the war?\"\n",
    "docs = vectordb.similarity_search(query)\n",
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving to the disk\n",
    "vectordb=Chroma.from_documents(documents=splits,embedding=embedding,persist_directory=\"./chroma_db\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To such a task we can dedicate our lives and our fortunes, everything that we are and everything that we have, with the pride of those who know that the day has come when America is privileged to spend her blood and her might for the principles that gave her birth and happiness and the peace which she has treasured. God helping her, she can do no other.\n"
     ]
    }
   ],
   "source": [
    "# load from disk\n",
    "db2 = Chroma(persist_directory=\"./chroma_db\", embedding_function=embedding)\n",
    "docs=db2.similarity_search(query)\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='To such a task we can dedicate our lives and our fortunes, everything that we are and everything that we have, with the pride of those who know that the day has come when America is privileged to spend her blood and her might for the principles that gave her birth and happiness and the peace which she has treasured. God helping her, she can do no other.', metadata={'source': 'speech.txt'}),\n",
       "  15573.843876438417),\n",
       " (Document(page_content='The world must be made safe for democracy. Its peace must be planted upon the tested foundations of political liberty. We have no selfish ends to serve. We desire no conquest, no dominion. We seek no indemnities for ourselves, no material compensation for the sacrifices we shall freely make. We are but one of the champions of the rights of mankind. We shall be satisfied when those rights have been made as secure as the faith and the freedom of nations can make them.', metadata={'source': 'speech.txt'}),\n",
       "  18241.307592374058),\n",
       " (Document(page_content='government in the hour of test. They are, most of them, as true and loyal Americans as if they had never known any other fealty or allegiance. They will be prompt to stand with us in rebuking and restraining the few who may be of a different mind and purpose. If there should be disloyalty, it will be dealt with with a firm hand of stern repression; but, if it lifts its head at all, it will lift it only here and there and without countenance except from a lawless and malignant few.', metadata={'source': 'speech.txt'}),\n",
       "  18734.93799256032),\n",
       " (Document(page_content='Just because we fight without rancor and without selfish object, seeking nothing for ourselves but what we shall wish to share with all free peoples, we shall, I feel confident, conduct our operations as belligerents without passion and ourselves observe with proud punctilio the principles of right and of fair play we profess to be fighting for.\\n\\n…', metadata={'source': 'speech.txt'}),\n",
       "  22469.371464645166)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## similarity Search With Score\n",
    "docs = vectordb.similarity_search_with_score(query)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To such a task we can dedicate our lives and our fortunes, everything that we are and everything that we have, with the pride of those who know that the day has come when America is privileged to spend her blood and her might for the principles that gave her birth and happiness and the peace which she has treasured. God helping her, she can do no other.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Retriever option\n",
    "retriever=vectordb.as_retriever()\n",
    "retriever.invoke(query)[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
